{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmKVSikY2kkwjxysWF/4wu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanushka365/SLEnergyConsumptionPrediction/blob/main/Time_Series_Forecasting_with_XGBoost2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAN8dCDiXpUk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "color_pal = sns.color_palette()\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../input/hourly-energy-consumption/PJME_hourly.csv')\n",
        "df = df.set_index('Datetime')\n",
        "df.index = pd.to_datetime(df.index)"
      ],
      "metadata": {
        "id": "CsH6i39pXuZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(style='.',\n",
        "        figsize=(15, 5),\n",
        "        color=color_pal[0],\n",
        "        title='PJME Energy Use in MW')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7f1Gb44oXx7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Outlier Analysis and removal[link text](https://)"
      ],
      "metadata": {
        "id": "nGq2tuCLX0fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['PJME_MW'].plot(kind='hist', bins=500)"
      ],
      "metadata": {
        "id": "4XmBTmWwX4Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.query('PJME_MW < 19_000')['PJME_MW'] \\\n",
        "    .plot(style='.',\n",
        "          figsize=(15, 5),\n",
        "          color=color_pal[5],\n",
        "          title='Outliers')"
      ],
      "metadata": {
        "id": "TyDnMzPrX8pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.query('PJME_MW > 19_000').copy()"
      ],
      "metadata": {
        "id": "dCZKnf8YX_GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reviewing: Train / Test Split"
      ],
      "metadata": {
        "id": "QLMmdzaXYDXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.loc[df.index < '01-01-2015']\n",
        "test = df.loc[df.index >= '01-01-2015']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "train.plot(ax=ax, label='Training Set', title='Data Train/Test Split')\n",
        "test.plot(ax=ax, label='Test Set')\n",
        "ax.axvline('01-01-2015', color='black', ls='--')\n",
        "ax.legend(['Training Set', 'Test Set'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LOrpA5R1YBSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Time Series Cross Validation"
      ],
      "metadata": {
        "id": "Gc7DHjohYIG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tss = TimeSeriesSplit(n_splits=5, test_size=24*365*1, gap=24)\n",
        "df = df.sort_index()"
      ],
      "metadata": {
        "id": "sZps88e3YGdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(5, 1, figsize=(15, 15), sharex=True)\n",
        "\n",
        "fold = 0\n",
        "for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "    train['PJME_MW'].plot(ax=axs[fold],\n",
        "                          label='Training Set',\n",
        "                          title=f'Data Train/Test Split Fold {fold}')\n",
        "    test['PJME_MW'].plot(ax=axs[fold],\n",
        "                         label='Test Set')\n",
        "    axs[fold].axvline(test.index.min(), color='black', ls='--')\n",
        "    fold += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bKGjEzZGYKyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting Horizon Explained\n",
        "\n",
        "The forecast horizon is the length of time into the future for which forecasts are to be prepared. These generally vary from short-term forecasting horizons (less than three months) to long-term horizons (more than two years)."
      ],
      "metadata": {
        "id": "ImY6LyifYOfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(df):\n",
        "    \"\"\"\n",
        "    Create time series features based on time series index.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['hour'] = df.index.hour\n",
        "    df['dayofweek'] = df.index.dayofweek\n",
        "    df['quarter'] = df.index.quarter\n",
        "    df['month'] = df.index.month\n",
        "    df['year'] = df.index.year\n",
        "    df['dayofyear'] = df.index.dayofyear\n",
        "    df['dayofmonth'] = df.index.day\n",
        "    df['weekofyear'] = df.index.isocalendar().week\n",
        "    return df\n",
        "\n",
        "df = create_features(df)"
      ],
      "metadata": {
        "id": "9MIRG4kfYMsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lag Features\n",
        "What was the target (x) days in the past."
      ],
      "metadata": {
        "id": "atvY6SWHYVuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_lags(df):\n",
        "    target_map = df['PJME_MW'].to_dict()\n",
        "    df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
        "    df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
        "    df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
        "    return df"
      ],
      "metadata": {
        "id": "efKiuIUgYVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = add_lags(df)"
      ],
      "metadata": {
        "id": "zr5MtqcUYbL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Using Cross Validation"
      ],
      "metadata": {
        "id": "a0C8jsM6Ych_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tss = TimeSeriesSplit(n_splits=5, test_size=24*365*1, gap=24)\n",
        "df = df.sort_index()\n",
        "\n",
        "\n",
        "fold = 0\n",
        "preds = []\n",
        "scores = []\n",
        "for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "\n",
        "    train = create_features(train)\n",
        "    test = create_features(test)\n",
        "\n",
        "    FEATURES = ['dayofyear', 'hour', 'dayofweek', 'quarter', 'month','year',\n",
        "                'lag1','lag2','lag3']\n",
        "    TARGET = 'PJME_MW'\n",
        "\n",
        "    X_train = train[FEATURES]\n",
        "    y_train = train[TARGET]\n",
        "\n",
        "    X_test = test[FEATURES]\n",
        "    y_test = test[TARGET]\n",
        "\n",
        "    reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
        "                           n_estimators=1000,\n",
        "                           early_stopping_rounds=50,\n",
        "                           objective='reg:linear',\n",
        "                           max_depth=3,\n",
        "                           learning_rate=0.01)\n",
        "    reg.fit(X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "            verbose=100)\n",
        "\n",
        "    y_pred = reg.predict(X_test)\n",
        "    preds.append(y_pred)\n",
        "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    scores.append(score)"
      ],
      "metadata": {
        "id": "chmuO8cVYekf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Score across folds {np.mean(scores):0.4f}')\n",
        "print(f'Fold scores:{scores}')"
      ],
      "metadata": {
        "id": "IWQ2cpjJYhLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the Future\n",
        "Retraining on all data\n",
        "To Predict the future we need an emtpy dataframe for future date ranges.\n",
        "Run those dates through our feature creation code + lag creation"
      ],
      "metadata": {
        "id": "dHO4mCUrYkQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain on all data\n",
        "df = create_features(df)\n",
        "\n",
        "FEATURES = ['dayofyear', 'hour', 'dayofweek', 'quarter', 'month', 'year',\n",
        "            'lag1','lag2','lag3']\n",
        "TARGET = 'PJME_MW'\n",
        "\n",
        "X_all = df[FEATURES]\n",
        "y_all = df[TARGET]\n",
        "\n",
        "reg = xgb.XGBRegressor(base_score=0.5,\n",
        "                       booster='gbtree',    \n",
        "                       n_estimators=500,\n",
        "                       objective='reg:linear',\n",
        "                       max_depth=3,\n",
        "                       learning_rate=0.01)\n",
        "reg.fit(X_all, y_all,\n",
        "        eval_set=[(X_all, y_all)],\n",
        "        verbose=100)"
      ],
      "metadata": {
        "id": "cSBcuw4sYjlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index.max()"
      ],
      "metadata": {
        "id": "vH--tCNRYqAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create future dataframe\n",
        "future = pd.date_range('2018-08-03','2019-08-01', freq='1h')\n",
        "future_df = pd.DataFrame(index=future)\n",
        "future_df['isFuture'] = True\n",
        "df['isFuture'] = False\n",
        "df_and_future = pd.concat([df, future_df])\n",
        "df_and_future = create_features(df_and_future)\n",
        "df_and_future = add_lags(df_and_future)"
      ],
      "metadata": {
        "id": "vFzETUnnYtPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_w_features = df_and_future.query('isFuture').copy()"
      ],
      "metadata": {
        "id": "CZ8yzeoOYvDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_w_features['pred'] = reg.predict(future_w_features[FEATURES])"
      ],
      "metadata": {
        "id": "QacCA9JqYvww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_w_features['pred'].plot(figsize=(10, 5),\n",
        "                               color=color_pal[4],\n",
        "                               ms=1,\n",
        "                               lw=1,\n",
        "                               title='Future Predictions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d-vVTS9PYydS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Saving Model For later"
      ],
      "metadata": {
        "id": "6Vlmt_nNY3E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "reg.save_model('model.json')"
      ],
      "metadata": {
        "id": "XcMGqhu0YzDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "id": "exzu2GxfY7UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_new = xgb.XGBRegressor()\n",
        "reg_new.load_model('model.json')\n",
        "future_w_features['pred'] = reg_new.predict(future_w_features[FEATURES])\n",
        "future_w_features['pred'].plot(figsize=(10, 5),\n",
        "                               color=color_pal[4],\n",
        "                               ms=1, lw=1,\n",
        "                               title='Future Predictions')\n"
      ],
      "metadata": {
        "id": "Y5PzVMdUY8LR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}